{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# ## uncomment for reproducibility ##\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "import time\n",
    "import itertools\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working locally\n"
     ]
    }
   ],
   "source": [
    "VERSION = '07'\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/gdrive')\n",
    "    root_path = 'gdrive/My Drive/Colab Notebooks/deep_mouse/'\n",
    "    print('Working on google colab')\n",
    "except:\n",
    "    root_path = '../'\n",
    "    print('Working locally')\n",
    "\n",
    "directory= f'{root_path}models/{VERSION}'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)    \n",
    "    \n",
    "sys.path.append(f'{root_path}/rsc/{VERSION}') # Adds pyLi directory to python modules path.\n",
    "from load_data import load_data\n",
    "from pre_process_data import pre_process_data\n",
    "from create_model import create_model\n",
    "from helper import play_bell, LossHistory, add_grid_and_save\n",
    "from train_model import train_model\n",
    "from run_training import run_training\n",
    "from parameter_space import Parameter_space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(params={}):\n",
    "    \n",
    "    grid_file_path = '{}/model_data/grid_{}.pkl'.format(root_path, VERSION)\n",
    "    \n",
    "    if os.path.isfile(grid_file_path):\n",
    "        grid_df = pd.read_pickle(grid_file_path)\n",
    "        test_index = grid_df['test_index'].max() + 1\n",
    "    else:\n",
    "        test_index = 0\n",
    "\n",
    "    current_grid = {\n",
    "        'version'                : ['str'     , VERSION],\n",
    "        'params'                 : ['O'       , params],\n",
    "        'test_index'             : [np.int    , test_index],\n",
    "        'root_path'              : ['str'     , root_path],\n",
    "        \n",
    "        # Load and preprocess\n",
    "        'batch_size_data'        : [np.int    , 200],\n",
    "        'x_std'                  : [np.float  , 3.398],\n",
    "        'y_std'                  : [np.float  , 2.926],\n",
    "        'sigma_cut'              : [np.float  , 0.1],\n",
    "        'training_size'          : [np.int    , 200],\n",
    "        \n",
    "        # Metrics\n",
    "        'dropout'                 : [np.float  , 0.],\n",
    "        'best_model_metric'      : ['str'     , 'val_acc'],\n",
    "        'training_metric'        : ['str'     , 'accuracy'],\n",
    "        \n",
    "        # Random seeds\n",
    "        'seed_skf'               : [np.int    , 0],\n",
    "        'seed_numpy'             : [np.int    , 0],\n",
    "        'seed_tensorflow'        : [np.int    , 0],\n",
    "        'seed_random'            : [np.int    , 0],\n",
    "        'seed_sklearn'           : [np.int    , 0],\n",
    "        'seed_model'             : [np.int    , 0],\n",
    "        \n",
    "        # Model properties\n",
    "        'input_shape'            : ['O'       , None],\n",
    "        'LSTM_size'              : [np.int    , 200],\n",
    "        'dropout'                : [np.float  , 0],\n",
    "        \n",
    "        # Training parameters\n",
    "        'learning_rate'          : [np.float  , 1.3e-4],\n",
    "        'batch_size'             : [np.int    , 32],\n",
    "        'epochs'                 : [np.int    , 200],\n",
    "        'test_size'              : [np.float  , 0.15],\n",
    "        'skf_n_splits'           : [np.int    , 5],\n",
    "        \n",
    "        # Outputs\n",
    "        'best_model_paths'       : ['O'       , []],\n",
    "        'best_model_accuracies'  : ['O'       , []],\n",
    "        'fit_outs'               : ['O'       , []]}\n",
    "\n",
    "    for key, value in params.items():\n",
    "        current_grid[key][1] = value\n",
    "    return current_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = create_grid()\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(grid)\n",
    "X_train, y_train = pre_process_data(X_train, y_train, grid)\n",
    "X_test, y_test = pre_process_data(X_test, y_test, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(next_point_to_probe):\n",
    "    print(f'Testing {next_point_to_probe}')\n",
    "    grid = create_grid(next_point_to_probe)\n",
    "    grid = run_training(X_train, y_train, grid, verbose=True)\n",
    "    \n",
    "    val_acc_history = [fit_out.history['val_acc'] for fit_out in grid.fit_outs]    \n",
    "    val_accuracy_estimator = np.mean(val_acc_history, 0)[130:180].mean()\n",
    "    return val_accuracy_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "ps = Parameter_space(bounds={\n",
    "    'LSTM_size' : (100, 300, 'int'),\n",
    "    'dropout' : (0, 0.3, 'linear')\n",
    "})\n",
    "\n",
    "ps.bayesopt(test_params, kappa=0.25)\n",
    "\n",
    "\n",
    "# ## BAYESIAN SEARCH\n",
    "grid_file_path = '{}/model_data/grid_{}.pkl'.format(root_path, VERSION)\n",
    "if os.path.isfile(grid_file_path):\n",
    "    grid_df = pd.read_pickle(grid_file_path)\n",
    "\n",
    "\n",
    "    for fo, param in zip(grid_df.fit_outs, grid_df.params):\n",
    "        somma = [x.history['val_acc'] for x in fo]    \n",
    "        s = np.mean(somma, 0)[130:180].mean()\n",
    "        ps.register_point(param, s)\n",
    "\n",
    "for _ in range(20):\n",
    "    next_point_to_probe = ps.get_random_next(time_seed=True)\n",
    "    target = test_params(next_point_to_probe)\n",
    "    ps.register_point(params=next_point_to_probe, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
