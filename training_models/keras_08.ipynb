{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# ## uncomment for reproducibility ##\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "import time\n",
    "import itertools\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "sys.path.append(\"../rsc\") # Adds pyLi directory to python modules path.\n",
    "# import lithium as li\n",
    "# import other as ot\n",
    "from load_data import load_data\n",
    "from pre_process_data import pre_process_data\n",
    "from create_model import create_model\n",
    "from helper import play_bell, LossHistory\n",
    "from train_model import train_model\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '08'\n",
    "\n",
    "directory= f'../models/{VERSION}'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(params={}):\n",
    "    if os.path.isfile('../model_data/grid_{}.pkl'.format(VERSION)):\n",
    "        grid_df = pd.read_pickle('../model_data/grid_{}.pkl'.format(VERSION))\n",
    "        test_index = grid_df['test_index'].max() + 1\n",
    "    else:\n",
    "        test_index = 0\n",
    "\n",
    "    current_grid = {\n",
    "        'version'                : ['str'     , VERSION],\n",
    "        'params'                 : ['O'       , params],\n",
    "        'test_index'             : [np.int    , test_index],\n",
    "        \n",
    "        # Load and preprocess\n",
    "        'batch_size_data'        : [np.int    , 200],\n",
    "        'x_std'                  : [np.float  , 3.398],\n",
    "        'y_std'                  : [np.float  , 2.926],\n",
    "        'sigma_cut'              : [np.float  , 0.1],\n",
    "        'training_size'          : [np.int    , 200],\n",
    "        \n",
    "        # Metrics\n",
    "        'dropout'                 : [np.float  , 0.],\n",
    "        'best_model_metric'      : ['str'     , 'val_acc'],\n",
    "        'training_metric'        : ['str'     , 'accuracy'],\n",
    "        \n",
    "        # Random seeds\n",
    "        'seed_skf'               : [np.int    , 0],\n",
    "        'seed_numpy'             : [np.int    , 0],\n",
    "        'seed_tensorflow'        : [np.int    , 0],\n",
    "        'seed_random'            : [np.int    , 0],\n",
    "        'seed_sklearn'           : [np.int    , 0],\n",
    "        'seed_model'             : [np.int    , 0],\n",
    "        \n",
    "        # Model properties\n",
    "        'input_shape'            : ['O'       , None],\n",
    "        'LSTM_size'              : [np.int    , 200],\n",
    "        'dropout'                : [np.float  , 0],\n",
    "        \n",
    "        # Training parameters\n",
    "        'learning_rate'          : [np.float  , 1.3e-4],\n",
    "        'batch_size'             : [np.int    , 32],\n",
    "        'epochs'                 : [np.int    , 200],\n",
    "        'test_size'              : [np.float  , 0.15],\n",
    "        'skf_n_splits'           : [np.int    , 5],\n",
    "        \n",
    "        # Outputs\n",
    "        'best_model_paths'       : ['O'       , []],\n",
    "        'best_model_accuracies'  : ['O'       , []],\n",
    "        'fit_outs'               : ['O'       , []]}\n",
    "\n",
    "    for key, value in params.items():\n",
    "        current_grid[key][1] = value\n",
    "    return current_grid\n",
    "\n",
    "def add_grid_and_save(grid):\n",
    "    if os.path.isfile('../model_data/grid_{}.pkl'.format(grid['version'][1])):\n",
    "        grid_df = pd.read_pickle('../model_data/grid_{}.pkl'.format(grid['version'][1]))\n",
    "    else:\n",
    "        grid_df = pd.DataFrame()\n",
    "        \n",
    "    grid_df = grid_df.append({key:grid[key][1] for key in grid.keys()}, ignore_index=True)        \n",
    "    grid_df.to_pickle('../model_data/grid_{}.pkl'.format(grid['version'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = create_grid()\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(grid)\n",
    "X_train, y_train = pre_process_data(X_train, y_train, grid)\n",
    "X_test, y_test = pre_process_data(X_test, y_test, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 199, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(training_points):\n",
    "    grid = create_grid({'training_size':training_points})\n",
    "    grid = run_training(X_train[:training_points, ...], y_train[:training_points], grid, verbose=True)\n",
    "    return np.mean(grid['best_model_accuracies'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(X, y, grid, verbose=True):\n",
    "    initial_time = time.time()\n",
    "    np.random.seed(grid['seed_numpy'][1])\n",
    "    tf.set_random_seed(grid['seed_tensorflow'][1])\n",
    "    random.seed(grid['seed_random'][1])\n",
    "\n",
    "    grid['input_shape'][1] = (X.shape[1], 2)\n",
    "    \n",
    "    \n",
    "    accuracies = []\n",
    "    for index_split in range(grid['skf_n_splits'][1]): # looping on uncompleted CV trainings\n",
    "        model = create_model(grid)\n",
    "        print(f\"\\nCV validation {index_split+1} of {grid['skf_n_splits'][1]}\")\n",
    "        best_model_path = '../models/{}/best_model_{}_{}.pkl'.format(grid['version'][1], grid['test_index'][1], index_split)\n",
    "        grid['best_model_paths'][1].append(best_model_path)\n",
    "        grid = train_model(X, y, model, grid)\n",
    "        grid['best_model_accuracies'][1].append(np.max(grid['fit_outs'][1][-1].history['val_acc']))\n",
    "    \n",
    "    add_grid_and_save(grid)\n",
    "\n",
    "    total_time = time.strftime(\"%H hours, %M min, %S sec\", time.gmtime((time.time() - initial_time)))\n",
    "    print('  --  Model trained in {}'.format(total_time))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV validation 1 of 5\n",
      "[####################] acc: 0.938 eta: 00 hours, 00 min, 00 sec\n",
      "CV validation 2 of 5\n",
      "[####################] acc: 0.938 eta: 00 hours, 00 min, 00 sec\n",
      "CV validation 3 of 5\n",
      "[####################] acc: 0.719 eta: 00 hours, 00 min, 00 sec\n",
      "CV validation 4 of 5\n",
      "[####################] acc: 0.969 eta: 00 hours, 00 min, 00 sec\n",
      "CV validation 5 of 5\n",
      "[####################] acc: 0.938 eta: 00 hours, 00 min, 00 sec  --  Model trained in 00 hours, 12 min, 00 sec\n",
      "Wall time: 12min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "local_path = '../model_data/grid_{}.pkl'.format(VERSION)\n",
    "drive_path = 'G:/Il mio Drive/Colab Notebooks/deep_mouse/model_data/grid_{}.pkl'.format(VERSION)\n",
    "\n",
    "if os.path.isfile(local_path):\n",
    "    grid_df = pd.read_pickle(local_path)\n",
    "\n",
    "for training_points in [100]:\n",
    "    target = test_params(training_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_df = pd.read_pickle(drive_path)\n",
    "local_df = pd.read_pickle(local_path)\n",
    "\n",
    "concat_path = '../model_data/grid_mix_{}.pkl'.format(VERSION)\n",
    "df = pd.concat([colab_df, local_df], axis=0, ignore_index=True)\n",
    "df.to_pickle(concat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
